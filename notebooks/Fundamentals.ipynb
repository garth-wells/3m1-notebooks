{
 "metadata": {
  "name": "",
  "signature": "sha256:3bddcebce0115fbb4930c0c6dd46053ea72088d957d4b2116cbf4cfcb94e0115"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Vectors, matrices and norms"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The notebook demonstrate the computation and use of some important concepts in linear algebra. NumPy is used for the numerical computations."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Vector norms"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The $l_{p}$-norm,of a vector $\\boldsymbol{x} \\in \\mathbb{R}^{n}$ is \n",
      "\n",
      "$$\n",
      "\\| \\boldsymbol{x} \\|_{p} = \\left( \\sum_{i=1}^{n} |x_{i}|^{p} \\right)^{1/p}\n",
      "$$\n",
      "\n",
      "Recall that when $p = \\infty$, we have have the maxiumum norm:\n",
      "\n",
      "$$\n",
      "\\| \\boldsymbol{x} \\|_{\\infty} = \\max(|x_{1}|, \\ldots , |x_{n}|)\n",
      "$$\n",
      "\n",
      "\n",
      "\n",
      "NumPy can compute $l_{p}$ norms of vectors. To see how, we first import NumPy and create a random vectors of length 10:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "np.random.seed(2)\n",
      "\n",
      "x = np.random.rand(10)\n",
      "print(x)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 0.4359949   0.02592623  0.54966248  0.43532239  0.4203678   0.33033482\n",
        "  0.20464863  0.61927097  0.29965467  0.26682728]\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can now compute a number of $l_{p}$ norms of $\\boldsymbol{x}$:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for p in range(1, 5):\n",
      "    x_norm = np.linalg.norm(x, p)\n",
      "    print(\"The l_{} norm of x is: {}\".format(p, x_norm))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The l_1 norm of x is: 3.58801017672\n",
        "The l_2 norm of x is: 1.24683424867\n",
        "The l_3 norm of x is: 0.901952092265\n",
        "The l_4 norm of x is: 0.77908583526\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For the $l_{\\infty}$ norm:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      " x_inf = np.linalg.norm(x, np.inf)\n",
      "print(\"The max norm of x is: {}\".format(x_inf))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The max norm of x is: 0.619270966351\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Matrix norms"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Norms of matrices can also be computed. The more interesting (and abstract) norms and *operator* norms. These are also known as *induced* norms."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Operator norms"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For an $n \\times n$ matrix $\\boldsymbol{A}$, the norm of the matrix is a measure of the maximum change in relative length it induces when applied to a vector. If we consider:  \n",
      "\n",
      "$$\n",
      "\\| \\boldsymbol{A}  \\boldsymbol{x} \\| \\le C \\| \\boldsymbol{x}\\| \\quad \\forall \\boldsymbol{x} \\in \\mathbb{R}^{d},\n",
      "$$\n",
      "\n",
      "then the smallest possible $C$ is the norm of $\\boldsymbol{A}$. The norm of $\\boldsymbol{A}$ is denoted by $\\|\\boldsymbol{A}\\|$:\n",
      "\n",
      "$$\n",
      "\\| \\boldsymbol{A}  \\boldsymbol{x} \\| \\le \\| \\boldsymbol{A}\\| \\| \\boldsymbol{x}\\| \\quad \\forall \\boldsymbol{x} \\in \\mathbb{R}^{d},\n",
      "$$\n",
      "\n",
      "The can be rearranged to provide the ussual definition of a matrix norm:\n",
      "\n",
      "$$\n",
      "\\| \\boldsymbol{A} \\| = \\max_{\\boldsymbol{x} \\in \\mathbb{R}^{n} \\backslash \\boldsymbol{0}}\n",
      "    \\frac{\\| \\boldsymbol{A} \\boldsymbol{x}\\|}{\\|\\boldsymbol{x}\\| }\n",
      "$$\n",
      "\n",
      "To compute actual norms of a matrix, we need to choose how we measure the length of a vector, i.e. which norm to use. If we choose the $l_{2}$-norm, then:\n",
      "\n",
      "$$\n",
      "\\| \\boldsymbol{A} \\|_{2} = \\max_{\\boldsymbol{x} \\in \\mathbb{R}^{n} \\backslash \\boldsymbol{0}}\n",
      "    \\frac{\\| \\boldsymbol{A} \\boldsymbol{x}\\|_{2}}{\\|\\boldsymbol{x}\\|_{2} }\n",
      "$$\n",
      "\n",
      "As discussed in the lectures, some norms are relatively inexpensive to compute for large matrices, and others are expensive. We can again use NumPy to compute some matrix norms. We first create a matrix filled with random numbers:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "A = np.random.rand(5, 5)\n",
      "print(A)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 0.62113383  0.52914209  0.13457995  0.51357812  0.18443987]\n",
        " [ 0.78533515  0.85397529  0.49423684  0.84656149  0.07964548]\n",
        " [ 0.50524609  0.0652865   0.42812233  0.09653092  0.12715997]\n",
        " [ 0.59674531  0.226012    0.10694568  0.22030621  0.34982629]\n",
        " [ 0.46778748  0.20174323  0.64040673  0.48306984  0.50523672]]\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(\"The l_1 norm of A is: {}\".format(np.linalg.norm(A, 1)))\n",
      "print(\"The l_2 norm of A is: {}\".format(np.linalg.norm(A, 2)))\n",
      "print(\"The max norm of A is: {}\".format(np.linalg.norm(A, np.inf)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The l_1 norm of A is: 2.97624786427\n",
        "The l_2 norm of A is: 2.19842668178\n",
        "The max norm of A is: 3.0597542402\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Vector-like norms"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It sometimes convenient to work with matrix norms that are similar to vector norms. A commonly used matrix norm is the Frobenius norm. It is analogous to the $l_{2}$ norm of a vector, as defined by\n",
      "\n",
      "$$\n",
      "\\|\\boldsymbol{A} \\|_{F} = \\left( \\sum_{i}\\sum_{i} a_{ij}^{2} \\right)^{1/2} \n",
      "$$\n",
      "\n",
      "To compute the Frobenius norm:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "A_frobenius = np.linalg.norm(A, 'fro')\n",
      "print(\"The Frobenius norm of A is: {}\".format(A_frobenius))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The Frobenius norm of A is: 2.34757581585\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Condition number"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The condition number of a matrix is important when working with matrices numerically because is tells us something about how stable algorithms will be with respect to round-off errors, and how fast some iterative techniques will converge. Recall that the condition number $\\kappa$ of a matrix $\\boldsymbol{A}$ is defined as:\n",
      "\n",
      "$$\n",
      "\\kappa(\\boldsymbol{A}) = \\| \\boldsymbol{A} \\| \\|\\boldsymbol{A}^{-1}\\|\n",
      "$$\n",
      "\n",
      "If we use the 2-norm, it was shown that:\n",
      "\n",
      "$$\n",
      "\\kappa_{2}(\\boldsymbol{A}) = \\frac{\\sqrt{\\lambda_{\\max}(\\boldsymbol{A}^{T}\\boldsymbol{A})}}{\\sqrt{\\lambda_{\\max}(\\boldsymbol{A}^{T}\\boldsymbol{A})}}\n",
      "$$"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Effect of poor conditioning on errors"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It was shown in lectures that when solving $\\boldsymbol{A} \\boldsymbol{x} = \\boldsymbol{b}$, if the condition number of $\\boldsymbol{A}$ is large, the small errors in $\\boldsymbol{b}$ can manifest themselves as large errors in the solution  $\\boldsymbol{x}$. We explor this now for the notoriously ill-conditioned *Hilbert matrix*. Entries of the Hilbert matrix $\\boldsymbol{H}$ are given by\n",
      "\n",
      "$$\n",
      "H_{ij} = \\frac{1}{i+j-1}\n",
      "$$\n",
      "\n",
      "We can use a SciPy function to create a $n \\times n$ Hilbert matrix:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import scipy.linalg as la\n",
      "\n",
      "H = la.hilbert(6)\n",
      "print(H)\n",
      "print(\"Condition number is: {}\".format(np.linalg.cond(A, 2)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 1.          0.5         0.33333333  0.25        0.2         0.16666667]\n",
        " [ 0.5         0.33333333  0.25        0.2         0.16666667  0.14285714]\n",
        " [ 0.33333333  0.25        0.2         0.16666667  0.14285714  0.125     ]\n",
        " [ 0.25        0.2         0.16666667  0.14285714  0.125       0.11111111]\n",
        " [ 0.2         0.16666667  0.14285714  0.125       0.11111111  0.1       ]\n",
        " [ 0.16666667  0.14285714  0.125       0.11111111  0.1         0.09090909]]\n",
        "Condition number is: 127.371483216\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Even for this small Hilbert matrix, the condition number is large.\n",
      "\n",
      "We now experiment with solving $\\boldsymbol{A} (\\boldsymbol{x}+ \\delta \\boldsymbol{x}) = \\boldsymbol{b} + \\delta \\boldsymbol{b}$, and compare the error $\\|\\delta{\\boldsymbol{x}}\\| / \\|\\boldsymbol{x}\\|$ to $\\|\\delta{\\boldsymbol{b}}\\| / \\|\\boldsymbol{b}\\|$. We will presume that the NumPy linear solvers can cope with the exact system $\\boldsymbol{A}\\boldsymbol{x} =\\boldsymbol{b}$.\n",
      "\n",
      "We first construct $\\boldsymbol{b}$, $\\delta\\boldsymbol{b}$ and $\\boldsymbol{b} + \\delta\\boldsymbol{b}$:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "b       = np.ones(H.shape[0])\n",
      "b_delta = 1.0e-6*np.random.rand(H.shape[0])\n",
      "\n",
      "# Perturbed RHS\n",
      "b1  = b + b_delta"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We now solve for $\\boldsymbol{A} \\boldsymbol{x}=  \\boldsymbol{b}$ and $\\boldsymbol{A} (\\boldsymbol{x}+ \\delta \\boldsymbol{x}) = \\boldsymbol{b} + \\delta \\boldsymbol{b}$:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x  = np.linalg.solve(H, b)\n",
      "x1 = np.linalg.solve(H, b1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We now compare $\\|\\delta{\\boldsymbol{x}}\\| / \\|\\boldsymbol{x}\\|$ and $\\|\\delta{\\boldsymbol{b}}\\| / \\|\\boldsymbol{b}\\|$:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "error_x = np.linalg.norm(x - x1, 2)/np.linalg.norm(x, 2)\n",
      "error_b = np.linalg.norm(b_delta, 2)/np.linalg.norm(b, 2)\n",
      "print(\"Relative in x and b: {}, {}\".format(error_x, error_b))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Relative in x and b: 0.000246062568055, 6.53669724523e-07\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Even for this small Hilbert matrix, a small error in $\\boldsymbol{b}$  leads to a much larger error in $\\boldsymbol{x}$. This will get worse with problem size.  We'll now put the test in side a loop to test larger matrices:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for n in (20, 100, 1000):\n",
      "    H = la.hilbert(n)\n",
      "    print(\"- For {} x {} matrix, the condition number is: {}\".format(n, n, np.linalg.cond(H, 2)))\n",
      "    \n",
      "    b       = np.ones(H.shape[0])\n",
      "    b_delta = 1.0e-6*np.random.rand(H.shape[0])\n",
      "    b1  = b + b_delta\n",
      "    \n",
      "    x  = np.linalg.solve(H, b)\n",
      "    x1 = np.linalg.solve(H, b1)\n",
      "    \n",
      "    error_x = np.linalg.norm(x - x1, 2)/np.linalg.norm(x, 2)\n",
      "    error_b = np.linalg.norm(b_delta, 2)/np.linalg.norm(b, 2)\n",
      "    print(\"   Relative in x and b: {}, {}\".format(error_x, error_b))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "- For 20 x 20 matrix, the condition number is: 8.78581438683e+17\n",
        "   Relative in x and b: 124.526951736, 6.17062872464e-07\n",
        "- For 100 x 100 matrix, the condition number is: 1.32900657828e+20\n",
        "   Relative in x and b: 721.819324724, 5.28597291328e-07\n",
        "- For 1000 x 1000 matrix, the condition number is: 4.49213279595e+20"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "   Relative in x and b: 43.1220728435, 5.71648031622e-07"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Condition number versus determinant"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It was discussed in lecture that the condition number of a matrix and its determinant are not necessarily related. Some small examples were presented. Here we consider some larger problems.\n",
      "\n",
      "We consider an $n \\times n$ upper triangular matrix filled with two, and one on the diagonal:\n",
      "\n",
      "$$\n",
      "\\boldsymbol{A} = \\begin{bmatrix} \n",
      "1 & 2 & \\ldots & 2 \n",
      "\\\\\n",
      "  & 1 & \\ddots & \\vdots \n",
      "\\\\\n",
      "  &   & \\ddots & 2\n",
      "\\\\\n",
      "   &  &        & 1\n",
      "\\end{bmatrix}\n",
      "$$\n",
      "\n",
      "This matrix has a determinant of one, and a condition number that grows with $n$. We can explore this with NumPy for increasing $n$."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def test_matrix(n):\n",
      "    A = np.zeros((n, n))\n",
      "    A[np.triu_indices(n)] = 2.0\n",
      "    np.fill_diagonal(A, 1.0)\n",
      "    return A\n",
      "\n",
      "for n in (2, 10, 100, 500):\n",
      "    A = test_matrix(n)\n",
      "    print(\"- Matrix size: {} x {}\".format(n, n))\n",
      "    print(\"   * l_2 condition number is: {}\".format(np.linalg.cond(A, 2)))\n",
      "    print(\"   * determinant is: {}\".format(np.linalg.det(A)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "- Matrix size: 2 x 2\n",
        "   * l_2 condition number is: 5.82842712475\n",
        "   * determinant is: 1.0\n",
        "- Matrix size: 10 x 10\n",
        "   * l_2 condition number is: 161.447638798\n",
        "   * determinant is: 1.0\n",
        "- Matrix size: 100 x 100\n",
        "   * l_2 condition number is: 16210.7227202\n",
        "   * determinant is: 1.0\n",
        "- Matrix size: 500 x 500\n",
        "   * l_2 condition number is: 405284.067903"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "   * determinant is: 1.0\n"
       ]
      }
     ],
     "prompt_number": 12
    }
   ],
   "metadata": {}
  }
 ]
}